package glance

import (
	"context"
	"fmt"
	"html/template"
	"log/slog"
	"net/http"
	// "net/url"
	"sort"
	"strings"
	"time"
	"os"
	"crypto/md5"
	"io"
	"path/filepath"
	"sync"
)

const videosWidgetPlaylistPrefix = "playlist:"

var (
	videosWidgetTemplate             = mustParseTemplate("videos.html", "widget-base.html", "video-card-contents.html")
	videosWidgetGridTemplate         = mustParseTemplate("videos-grid.html", "widget-base.html", "video-card-contents.html")
	videosWidgetVerticalListTemplate = mustParseTemplate("videos-vertical-list.html", "widget-base.html")
)

type videosWidget struct {
	widgetBase        `yaml:",inline"`
	Videos            videoList `yaml:"-"`
	VideoUrlTemplate  string    `yaml:"video-url-template"`
	Style             string    `yaml:"style"`
	CollapseAfter     int       `yaml:"collapse-after"`
	CollapseAfterRows int       `yaml:"collapse-after-rows"`
	Channels          []string  `yaml:"channels"`
	Playlists         []string  `yaml:"playlists"`
	Limit             int       `yaml:"limit"`
	IncludeShorts     bool      `yaml:"include-shorts"`
}

type bilibiliSpaceResponseJson struct {
	Data struct {
		Item []struct {
			Title  string `json:"title"`
			Cover  string `json:"cover"`
			Ctime  int64  `json:"ctime"`
			Author string `json:"author"`
			Bvid   string `json:"bvid"`
		} `json:"item"`
	} `json:"data"`
}

// å›¾ç‰‡ç¼“å­˜ç®¡ç†å™¨
type ImageCache struct {
    cacheDir      string
    cacheDuration time.Duration
    downloading   map[string]chan struct{} // é˜²æ­¢é‡å¤ä¸‹è½½
    mutex         sync.RWMutex
}

// åˆ›å»ºå›¾ç‰‡ç¼“å­˜ç®¡ç†å™¨
func NewImageCache(cacheDir string, duration time.Duration) *ImageCache {
    // ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
    if err := os.MkdirAll(cacheDir, 0755); err != nil {
        slog.Error("Failed to create cache directory", "dir", cacheDir, "error", err)
    }

    return &ImageCache{
        cacheDir:      cacheDir,
        cacheDuration: duration,
        downloading:   make(map[string]chan struct{}),
    }
}

// ç”Ÿæˆç¼“å­˜æ–‡ä»¶å
func (ic *ImageCache) getCacheFileName(url string) string {
    hash := md5.Sum([]byte(url))
    
    // æ ¹æ®URLç¡®å®šæ–‡ä»¶æ‰©å±•å
    ext := ".jpg" // é»˜è®¤
    if strings.Contains(url, ".png") {
        ext = ".png"
    } else if strings.Contains(url, ".webp") {
        ext = ".webp"
    } else if strings.Contains(url, ".gif") {
        ext = ".gif"
    }
    
    return fmt.Sprintf("%x%s", hash, ext)
}

// è·å–ç¼“å­˜æ–‡ä»¶å®Œæ•´è·¯å¾„
func (ic *ImageCache) getCacheFilePath(url string) string {
    return filepath.Join(ic.cacheDir, ic.getCacheFileName(url))
}

// æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
func (ic *ImageCache) isCacheValid(filePath string) bool {
    info, err := os.Stat(filePath)
    if err != nil {
        return false
    }
    
    // æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨æœ‰æ•ˆæœŸå†…
    return time.Since(info.ModTime()) < ic.cacheDuration
}

// ä¸‹è½½å›¾ç‰‡åˆ°ç¼“å­˜
func (ic *ImageCache) downloadImage(url, filePath string) error {
    // åˆ›å»ºå¸¦æœ‰é˜²ç›—é“¾å¤´éƒ¨çš„è¯·æ±‚
    req, err := http.NewRequest("GET", url, nil)
    if err != nil {
        return fmt.Errorf("create request failed: %w", err)
    }
    
    // ğŸ”‘ å…³é”®ï¼šè®¾ç½®è¯·æ±‚å¤´ç»•è¿‡Bç«™é˜²ç›—é“¾
    req.Header.Set("User-Agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    req.Header.Set("Referer", "https://www.bilibili.com/")
    req.Header.Set("Accept", "image/webp,image/apng,image/*,*/*;q=0.8")
    req.Header.Set("Accept-Language", "zh-CN,zh;q=0.9")
    req.Header.Set("Cache-Control", "no-cache")
    req.Header.Set("Sec-Fetch-Dest", "image")
    req.Header.Set("Sec-Fetch-Mode", "no-cors")
    req.Header.Set("Sec-Fetch-Site", "cross-site")
    
    client := &http.Client{
        Timeout: 15 * time.Second,
        Transport: &http.Transport{
            MaxIdleConns:       10,
            IdleConnTimeout:    30 * time.Second,
        },
    }
    
    resp, err := client.Do(req)
    if err != nil {
        return fmt.Errorf("request failed: %w", err)
    }
    defer resp.Body.Close()
    
    if resp.StatusCode != http.StatusOK {
        return fmt.Errorf("bad status code: %d", resp.StatusCode)
    }
    
    // åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼Œé¿å…éƒ¨åˆ†ä¸‹è½½çš„æ–‡ä»¶è¢«ä½¿ç”¨
    tempPath := filePath + ".tmp"
    file, err := os.Create(tempPath)
    if err != nil {
        return fmt.Errorf("create temp file failed: %w", err)
    }
    
    // ä¸‹è½½å›¾ç‰‡å†…å®¹
    _, err = io.Copy(file, resp.Body)
    file.Close()
    
    if err != nil {
        os.Remove(tempPath) // æ¸…ç†å¤±è´¥çš„ä¸´æ—¶æ–‡ä»¶
        return fmt.Errorf("download failed: %w", err)
    }
    
    // åŸå­æ€§ç§»åŠ¨æ–‡ä»¶
    if err := os.Rename(tempPath, filePath); err != nil {
        os.Remove(tempPath)
        return fmt.Errorf("move temp file failed: %w", err)
    }
    
    slog.Info("Image cached successfully", "url", url, "path", filePath)
    return nil
}

// è·å–ç¼“å­˜çš„å›¾ç‰‡URLï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
func (ic *ImageCache) GetCachedImageURL(originalURL string) string {
    if originalURL == "" {
        return ""
    }
    
    // ç¡®ä¿ä½¿ç”¨ HTTPS
    if strings.HasPrefix(originalURL, "http://") {
        originalURL = strings.Replace(originalURL, "http://", "https://", 1)
    }
    
    filePath := ic.getCacheFilePath(originalURL)
    fileName := ic.getCacheFileName(originalURL)
    
    // å¦‚æœç¼“å­˜æœ‰æ•ˆï¼Œç›´æ¥è¿”å›ç¼“å­˜URL
    if ic.isCacheValid(filePath) {
        return "/cache/images/" + fileName
    }
    
    // é˜²æ­¢åŒä¸€å›¾ç‰‡é‡å¤ä¸‹è½½
    ic.mutex.Lock()
    if ch, exists := ic.downloading[originalURL]; exists {
        ic.mutex.Unlock()
        // ç­‰å¾…å…¶ä»–goroutineä¸‹è½½å®Œæˆ
        <-ch
        if ic.isCacheValid(filePath) {
            return "/cache/images/" + fileName
        }
    } else {
        // æ ‡è®°æ­£åœ¨ä¸‹è½½
        ch := make(chan struct{})
        ic.downloading[originalURL] = ch
        ic.mutex.Unlock()
        
        // ä¸‹è½½å›¾ç‰‡
        go func() {
            defer func() {
                close(ch)
                ic.mutex.Lock()
                delete(ic.downloading, originalURL)
                ic.mutex.Unlock()
            }()
            
            if err := ic.downloadImage(originalURL, filePath); err != nil {
                slog.Error("Failed to download image", "url", originalURL, "error", err)
            }
        }()
    }
    
    // æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ—§ç¼“å­˜ï¼ˆå³ä½¿è¿‡æœŸä¹Ÿå…ˆç”¨ç€ï¼‰
    if _, err := os.Stat(filePath); err == nil {
        return "/cache/images/" + fileName
    }
    
    // å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œè¿”å›åŸå§‹URLä½œä¸ºåå¤‡
    return originalURL
}

// é¢„åŠ è½½å›¾ç‰‡åˆ°ç¼“å­˜ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰
func (ic *ImageCache) PreloadImage(originalURL string) {
    if originalURL == "" {
        return
    }
    
    // ç¡®ä¿ä½¿ç”¨ HTTPS
    if strings.HasPrefix(originalURL, "http://") {
        originalURL = strings.Replace(originalURL, "http://", "https://", 1)
    }
    
    filePath := ic.getCacheFilePath(originalURL)
    
    // å¦‚æœå·²ç»ç¼“å­˜ä¸”æœ‰æ•ˆï¼Œè·³è¿‡
    if ic.isCacheValid(filePath) {
        return
    }
    
    // é˜²æ­¢é‡å¤ä¸‹è½½
    ic.mutex.Lock()
    if _, exists := ic.downloading[originalURL]; exists {
        ic.mutex.Unlock()
        return
    }
    
    ch := make(chan struct{})
    ic.downloading[originalURL] = ch
    ic.mutex.Unlock()
    
    // å¼‚æ­¥ä¸‹è½½
    go func() {
        defer func() {
            close(ch)
            ic.mutex.Lock()
            delete(ic.downloading, originalURL)
            ic.mutex.Unlock()
        }()
        
        if err := ic.downloadImage(originalURL, filePath); err != nil {
            slog.Error("Failed to preload image", "url", originalURL, "error", err)
        }
    }()
}

// æ¸…ç†è¿‡æœŸç¼“å­˜
func (ic *ImageCache) CleanExpiredCache() {
    files, err := filepath.Glob(filepath.Join(ic.cacheDir, "*"))
    if err != nil {
        slog.Error("Failed to list cache files", "error", err)
        return
    }
    
    var cleaned int
    var totalSize int64
    
    for _, file := range files {
        info, err := os.Stat(file)
        if err != nil {
            continue
        }
        
        // åˆ é™¤è¿‡æœŸæ–‡ä»¶
        if time.Since(info.ModTime()) > ic.cacheDuration {
            if err := os.Remove(file); err == nil {
                cleaned++
                totalSize += info.Size()
            }
        }
    }
    
    if cleaned > 0 {
        slog.Info("Cache cleanup completed", 
            "files_removed", cleaned, 
            "space_freed", fmt.Sprintf("%.2fMB", float64(totalSize)/(1024*1024)))
    }
}

// å…¨å±€å›¾ç‰‡ç¼“å­˜å®ä¾‹
var globalImageCache = NewImageCache("/root/glance/glance-main/cache/images", 24*time.Hour)

func (widget *videosWidget) initialize() error {
	widget.withTitle("Videos").withCacheDuration(time.Hour)

	if widget.Limit <= 0 {
		widget.Limit = 25
	}

	if widget.CollapseAfterRows == 0 || widget.CollapseAfterRows < -1 {
		widget.CollapseAfterRows = 4
	}

	if widget.CollapseAfter == 0 || widget.CollapseAfter < -1 {
		widget.CollapseAfter = 7
	}

	// A bit cheeky, but from a user's perspective it makes more sense when channels and
	// playlists are separate things rather than specifying a list of channels and some of
	// them awkwardly have a "playlist:" prefix
	if len(widget.Playlists) > 0 {
		initialLen := len(widget.Channels)
		widget.Channels = append(widget.Channels, make([]string, len(widget.Playlists))...)

		for i := range widget.Playlists {
			widget.Channels[initialLen+i] = videosWidgetPlaylistPrefix + widget.Playlists[i]
		}
	}

	return nil
}

func (widget *videosWidget) update(ctx context.Context) {
	videos, err := fetchYoutubeChannelUploads(widget.Channels, widget.VideoUrlTemplate, widget.IncludeShorts)

	if !widget.canContinueUpdateAfterHandlingErr(err) {
		return
	}

	if len(videos) > widget.Limit {
		videos = videos[:widget.Limit]
	}

	widget.Videos = videos
}

func (widget *videosWidget) Render() template.HTML {
	var template *template.Template

	switch widget.Style {
	case "grid-cards":
		template = videosWidgetGridTemplate
	case "vertical-list":
		template = videosWidgetVerticalListTemplate
	default:
		template = videosWidgetTemplate
	}

	return widget.renderTemplate(widget, template)
}

type youtubeFeedResponseXml struct {
	Channel     string `xml:"author>name"`
	ChannelLink string `xml:"author>uri"`
	Videos      []struct {
		Title     string `xml:"title"`
		Published string `xml:"published"`
		Link      struct {
			Href string `xml:"href,attr"`
		} `xml:"link"`

		Group struct {
			Thumbnail struct {
				Url string `xml:"url,attr"`
			} `xml:"http://search.yahoo.com/mrss/ thumbnail"`
		} `xml:"http://search.yahoo.com/mrss/ group"`
	} `xml:"entry"`
}

func parseYoutubeFeedTime(t string) time.Time {
	parsedTime, err := time.Parse("2006-01-02T15:04:05-07:00", t)
	if err != nil {
		return time.Now()
	}

	return parsedTime
}

type video struct {
	ThumbnailUrl string
	Title        string
	Url          string
	Author       string
	AuthorUrl    string
	TimePosted   time.Time
	Cover        string
	Ctime        int64
	Bvid         string
}


type videoList []video

func (v videoList) sortByNewest() videoList {
	sort.Slice(v, func(i, j int) bool {
		return v[i].TimePosted.After(v[j].TimePosted)
	})

	return v
}

// func fetchYoutubeChannelUploads(channelOrPlaylistIDs []string, videoUrlTemplate string, includeShorts bool) (videoList, error) {
// 	requests := make([]*http.Request, 0, len(channelOrPlaylistIDs))

// 	for i := range channelOrPlaylistIDs {
// 		var feedUrl string
// 		if strings.HasPrefix(channelOrPlaylistIDs[i], videosWidgetPlaylistPrefix) {
// 			feedUrl = "https://www.youtube.com/feeds/videos.xml?playlist_id=" +
// 				strings.TrimPrefix(channelOrPlaylistIDs[i], videosWidgetPlaylistPrefix)
// 		} else if !includeShorts && strings.HasPrefix(channelOrPlaylistIDs[i], "UC") {
// 			playlistId := strings.Replace(channelOrPlaylistIDs[i], "UC", "UULF", 1)
// 			feedUrl = "https://www.youtube.com/feeds/videos.xml?playlist_id=" + playlistId
// 		} else {
// 			feedUrl = "https://www.youtube.com/feeds/videos.xml?channel_id=" + channelOrPlaylistIDs[i]
// 		}

// 		request, _ := http.NewRequest("GET", feedUrl, nil)
// 		requests = append(requests, request)
// 	}

// 	job := newJob(decodeXmlFromRequestTask[youtubeFeedResponseXml](defaultHTTPClient), requests).withWorkers(30)
// 	responses, errs, err := workerPoolDo(job)
// 	if err != nil {
// 		return nil, fmt.Errorf("%w: %v", errNoContent, err)
// 	}

// 	videos := make(videoList, 0, len(channelOrPlaylistIDs)*15)
// 	var failed int

// 	for i := range responses {
// 		if errs[i] != nil {
// 			failed++
// 			slog.Error("Failed to fetch youtube feed", "channel", channelOrPlaylistIDs[i], "error", errs[i])
// 			continue
// 		}

// 		response := responses[i]

// 		for j := range response.Videos {
// 			v := &response.Videos[j]
// 			var videoUrl string

// 			if videoUrlTemplate == "" {
// 				videoUrl = v.Link.Href
// 			} else {
// 				parsedUrl, err := url.Parse(v.Link.Href)

// 				if err == nil {
// 					videoUrl = strings.ReplaceAll(videoUrlTemplate, "{VIDEO-ID}", parsedUrl.Query().Get("v"))
// 				} else {
// 					videoUrl = "#"
// 				}
// 			}

// 			videos = append(videos, video{
// 				ThumbnailUrl: v.Group.Thumbnail.Url,
// 				Title:        v.Title,
// 				Url:          videoUrl,
// 				Author:       response.Channel,
// 				AuthorUrl:    response.ChannelLink + "/videos",
// 				TimePosted:   parseYoutubeFeedTime(v.Published),
// 			})
// 		}
// 	}
func fetchYoutubeChannelUploads(channelOrPlaylistIDs []string, videoUrlTemplate string, includeShorts bool) (videoList, error) {
	requests := make([]*http.Request, 0, len(channelOrPlaylistIDs))
	u := "https://app.bilibili.com/x/v2/space/archive/cursor?vmid="
	for i := range channelOrPlaylistIDs {
		request, _ := http.NewRequest("GET", u+channelOrPlaylistIDs[i], nil)
		request.Header.Set("User-Agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
		request.Header.Set("Referer", "https://www.bilibili.com/")

		requests = append(requests, request)
	}

	job := newJob(decodeJsonFromRequestTask[bilibiliSpaceResponseJson](defaultHTTPClient), requests).withWorkers(30)

	responses, errs, err := workerPoolDo(job)

	if err != nil {
		return nil, fmt.Errorf("%w: %v", errNoContent, err)
	}

	videos := make(videoList, 0, len(channelOrPlaylistIDs)*15)
	var failed int
	for i := range responses {
		if errs[i] != nil {
			failed++
			slog.Error("Failed to fetch bilibili feed", "uid", channelOrPlaylistIDs[i], "error", errs[i])
			continue
		}
		response := responses[i]
		for j := range response.Data.Item {
			bilivideo := &response.Data.Item[j]
			videoUrl := `https://www.bilibili.com/video/` + bilivideo.Bvid

			// ğŸ¯ æ ¸å¿ƒä¿®æ”¹ï¼šä½¿ç”¨çœŸæ­£çš„ç¼“å­˜æœºåˆ¶
            // cachedImageURL := globalImageCache.GetCachedImageURL(bilivideo.Cover)
            
            // // é¢„åŠ è½½å›¾ç‰‡ï¼ˆå¯é€‰ï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼‰
            // globalImageCache.PreloadImage(bilivideo.Cover)
            
            // fmt.Printf("Original cover: %s\n", bilivideo.Cover)
            // fmt.Printf("Cached cover: %s\n", cachedImageURL)

			videos = append(videos, video{
				ThumbnailUrl: bilivideo.Cover,
				// ThumbnailUrl: cachedImageURL,
				Title:        bilivideo.Title,
				Url:          strings.ReplaceAll(videoUrl, "http://", "https://"),
				Author:       bilivideo.Author,
				AuthorUrl:    `https://space.bilibili.com/` + channelOrPlaylistIDs[i],
				TimePosted:   time.Unix(bilivideo.Ctime, 0),
			})
		}
	}

	if len(videos) == 0 {
		return nil, errNoContent
	}

	videos.sortByNewest()

	if failed > 0 {
		return videos, fmt.Errorf("%w: missing videos from %d channels", errPartialContent, failed)
	}

	return videos, nil
}
